{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUdZ8Izq9tJgk/+XLbXArS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f24af718d0cf4505a2d0a2e242be3838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0ed9234ded94763a0ff018894bf9c13",
              "IPY_MODEL_03a5198e348c4997991aea91a0eeff1a",
              "IPY_MODEL_b316ff0d140941b689cc01e122c82469"
            ],
            "layout": "IPY_MODEL_da169dfb9f6d424aa7039b9b4c5cd6fd"
          }
        },
        "b0ed9234ded94763a0ff018894bf9c13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_347983119bc147f19506e0339f238914",
            "placeholder": "​",
            "style": "IPY_MODEL_7ddde82d810d44fdb11c8f8cb3bd8e6e",
            "value": "README.md: 100%"
          }
        },
        "03a5198e348c4997991aea91a0eeff1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec5c60c8acea4d3fa3bdb5e7893fe667",
            "max": 65391,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d930c42f86bb4375b06f9e65b8cb3eba",
            "value": 65391
          }
        },
        "b316ff0d140941b689cc01e122c82469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6a012afb0dd40a7bf9b858ef111b940",
            "placeholder": "​",
            "style": "IPY_MODEL_ecd66e1007bc4560b585e6c651dc0baa",
            "value": " 65.4k/65.4k [00:00&lt;00:00, 2.36MB/s]"
          }
        },
        "da169dfb9f6d424aa7039b9b4c5cd6fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "347983119bc147f19506e0339f238914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ddde82d810d44fdb11c8f8cb3bd8e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec5c60c8acea4d3fa3bdb5e7893fe667": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d930c42f86bb4375b06f9e65b8cb3eba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6a012afb0dd40a7bf9b858ef111b940": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecd66e1007bc4560b585e6c651dc0baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbb7abf0456b488b8c1ce34f1ecd940f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf7f61e4de3f4e789182f2e89d08c43c",
              "IPY_MODEL_cfd98dc31c794b8dbce58935064584b8",
              "IPY_MODEL_3b83cef72e604ebdbd3230fbbd30839c"
            ],
            "layout": "IPY_MODEL_0c0f419153f341cca3f3a6f5b3babc50"
          }
        },
        "bf7f61e4de3f4e789182f2e89d08c43c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_553072e7dbe648ffae7719a37e7db6bc",
            "placeholder": "​",
            "style": "IPY_MODEL_892ab796c2ff4127bbe71ede3ddd3415",
            "value": "test-00000-of-00001.parquet: 100%"
          }
        },
        "cfd98dc31c794b8dbce58935064584b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e864c2ca8be9438b863a753abccbbb9f",
            "max": 131945,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4e4c61479284f85b49343bc0cef332c",
            "value": 131945
          }
        },
        "3b83cef72e604ebdbd3230fbbd30839c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3fa44dc410d47b2afc66ec7b1d9f194",
            "placeholder": "​",
            "style": "IPY_MODEL_958b768de2524aaab11101cf17e989ed",
            "value": " 132k/132k [00:00&lt;00:00, 3.36MB/s]"
          }
        },
        "0c0f419153f341cca3f3a6f5b3babc50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "553072e7dbe648ffae7719a37e7db6bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "892ab796c2ff4127bbe71ede3ddd3415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e864c2ca8be9438b863a753abccbbb9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4e4c61479284f85b49343bc0cef332c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3fa44dc410d47b2afc66ec7b1d9f194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "958b768de2524aaab11101cf17e989ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a08b0bf503d44258c411a656151ee7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b815c8de147d44f88f1ebf0bc379e7b4",
              "IPY_MODEL_0c38740172e9434e962c88174baf69ce",
              "IPY_MODEL_2152d5e5054a4cb9b64c3a400d3a400c"
            ],
            "layout": "IPY_MODEL_ee908459639d4fbc9a3a1214c9880d7c"
          }
        },
        "b815c8de147d44f88f1ebf0bc379e7b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4890ddd63de74b59a1123fbc94085df4",
            "placeholder": "​",
            "style": "IPY_MODEL_57ae130e780b44a5bdf8170ee72ba35d",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "0c38740172e9434e962c88174baf69ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15ec8e4bf3ef41ecab394e5004108854",
            "max": 57148882,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8bbb0d9ba7f42feb64ef1fc23fd9e5c",
            "value": 57148882
          }
        },
        "2152d5e5054a4cb9b64c3a400d3a400c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5fa6b7e7d1446109ea1b0091dbc1c88",
            "placeholder": "​",
            "style": "IPY_MODEL_65016476122c4606b2525fb15d04cabd",
            "value": " 57.1M/57.1M [00:01&lt;00:00, 27.2MB/s]"
          }
        },
        "ee908459639d4fbc9a3a1214c9880d7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4890ddd63de74b59a1123fbc94085df4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57ae130e780b44a5bdf8170ee72ba35d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15ec8e4bf3ef41ecab394e5004108854": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8bbb0d9ba7f42feb64ef1fc23fd9e5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5fa6b7e7d1446109ea1b0091dbc1c88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65016476122c4606b2525fb15d04cabd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77b57dc4a5534d8db8c720cb7f58ea58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5cbceabcecb546869728f3e1ca6051d6",
              "IPY_MODEL_858116ce3ed344299bba909b05add80c",
              "IPY_MODEL_23d29a32f4264099afec134f8c663509"
            ],
            "layout": "IPY_MODEL_f511701fc82f45889a87650557adc2af"
          }
        },
        "5cbceabcecb546869728f3e1ca6051d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07b45ce1c5ba492da7c9ced86ce0cd81",
            "placeholder": "​",
            "style": "IPY_MODEL_45e8a4d2261349dcb19199e8006d5abd",
            "value": "validation-00000-of-00001.parquet: 100%"
          }
        },
        "858116ce3ed344299bba909b05add80c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58350931d5ac497caeb85f0f36abd8da",
            "max": 132009,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0a5a06ee5ae4d89892107f0c7c504c3",
            "value": 132009
          }
        },
        "23d29a32f4264099afec134f8c663509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b93235341244881b27fc54c604a10dc",
            "placeholder": "​",
            "style": "IPY_MODEL_df98a38752f143f9976ae4e4ab79d811",
            "value": " 132k/132k [00:00&lt;00:00, 4.97MB/s]"
          }
        },
        "f511701fc82f45889a87650557adc2af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07b45ce1c5ba492da7c9ced86ce0cd81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45e8a4d2261349dcb19199e8006d5abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58350931d5ac497caeb85f0f36abd8da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0a5a06ee5ae4d89892107f0c7c504c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b93235341244881b27fc54c604a10dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df98a38752f143f9976ae4e4ab79d811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b82cf4186514ce4bb3788273a849808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_782a48514338428d94415662bf276399",
              "IPY_MODEL_3fc6ef0691a943c3ac80beadb8457ffa",
              "IPY_MODEL_91795100b6f94381bf11b1a632ffe9c0"
            ],
            "layout": "IPY_MODEL_bb91939f39ae4d6199aa394f18ab7e79"
          }
        },
        "782a48514338428d94415662bf276399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb5206954b1044b983e290ac9d8f11a7",
            "placeholder": "​",
            "style": "IPY_MODEL_6027294d496a464e8b2f5a0e4f439e0b",
            "value": "Generating test split: 100%"
          }
        },
        "3fc6ef0691a943c3ac80beadb8457ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_682b0634ad4d4499a8f3271240ad2cb1",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a81e719a1b0c4498b7e4ff61a808f90c",
            "value": 2000
          }
        },
        "91795100b6f94381bf11b1a632ffe9c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_324424da5de94d15a5fec0803401c7c1",
            "placeholder": "​",
            "style": "IPY_MODEL_1ca486c6a4f248d0ba4c2f951498912c",
            "value": " 2000/2000 [00:00&lt;00:00, 52784.44 examples/s]"
          }
        },
        "bb91939f39ae4d6199aa394f18ab7e79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb5206954b1044b983e290ac9d8f11a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6027294d496a464e8b2f5a0e4f439e0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "682b0634ad4d4499a8f3271240ad2cb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a81e719a1b0c4498b7e4ff61a808f90c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "324424da5de94d15a5fec0803401c7c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ca486c6a4f248d0ba4c2f951498912c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3bb565c9058403296011a5cbbc8487f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_752041188e5a495ebf8c3d3bb7c90d20",
              "IPY_MODEL_d6a64ce897ab4aedbc792e001fc4a45a",
              "IPY_MODEL_a22c8e12458747458c6a44197ad4e297"
            ],
            "layout": "IPY_MODEL_6eedaba0e6d14b3cb3e84e273b20ed79"
          }
        },
        "752041188e5a495ebf8c3d3bb7c90d20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85c63db23bd84b7589b6c64e29678f83",
            "placeholder": "​",
            "style": "IPY_MODEL_d191572d3a984e9e980ce1b6dc5a77a4",
            "value": "Generating train split: 100%"
          }
        },
        "d6a64ce897ab4aedbc792e001fc4a45a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94cae0cdaed24d67bac8de4a76f9e9a8",
            "max": 1000000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cff60b15dc3d48378cc5a5cc22dc9c91",
            "value": 1000000
          }
        },
        "a22c8e12458747458c6a44197ad4e297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b62e7f169c3043738298c2a833eb7cc3",
            "placeholder": "​",
            "style": "IPY_MODEL_87be7681cbf14773933397cb1199dfaa",
            "value": " 1000000/1000000 [00:01&lt;00:00, 736444.80 examples/s]"
          }
        },
        "6eedaba0e6d14b3cb3e84e273b20ed79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85c63db23bd84b7589b6c64e29678f83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d191572d3a984e9e980ce1b6dc5a77a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94cae0cdaed24d67bac8de4a76f9e9a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cff60b15dc3d48378cc5a5cc22dc9c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b62e7f169c3043738298c2a833eb7cc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87be7681cbf14773933397cb1199dfaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56fb3225660140deb53709acb4cc84f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa6971a6e35d49c491628d468e4f55e9",
              "IPY_MODEL_cc4f7f13aa92498fa7750d1ebe3020e3",
              "IPY_MODEL_fa46732dc7e2472a92a0051b52659849"
            ],
            "layout": "IPY_MODEL_b74d754249f24a6eb07bb13678ac0faa"
          }
        },
        "aa6971a6e35d49c491628d468e4f55e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e5869811a6440d69beaa00776043e4f",
            "placeholder": "​",
            "style": "IPY_MODEL_cf9d9eebd5354a2a9d21a732fd1a9245",
            "value": "Generating validation split: 100%"
          }
        },
        "cc4f7f13aa92498fa7750d1ebe3020e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e58642178f94b24af5edf6a946ff8f3",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa42c89d50434f48a3cb9847fdbe8a45",
            "value": 2000
          }
        },
        "fa46732dc7e2472a92a0051b52659849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe5c7127f69f41c4b0c16cf80d5833e0",
            "placeholder": "​",
            "style": "IPY_MODEL_c77fb2f4a2f349e8a94d4f00d5f05a59",
            "value": " 2000/2000 [00:00&lt;00:00, 53803.48 examples/s]"
          }
        },
        "b74d754249f24a6eb07bb13678ac0faa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e5869811a6440d69beaa00776043e4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf9d9eebd5354a2a9d21a732fd1a9245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e58642178f94b24af5edf6a946ff8f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa42c89d50434f48a3cb9847fdbe8a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe5c7127f69f41c4b0c16cf80d5833e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c77fb2f4a2f349e8a94d4f00d5f05a59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gwegayhu/dashboards-app/blob/master/PragMind_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FOUenTP_s_Wk",
        "outputId": "8fd9da8b-017b-4868-c52e-f89c9e93e535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.0.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.0.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tokenizers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cTBamvZItHnA",
        "outputId": "d9890ec7-4df2-468b-abf8-19dd4b32b9a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "f24af718d0cf4505a2d0a2e242be3838",
            "b0ed9234ded94763a0ff018894bf9c13",
            "03a5198e348c4997991aea91a0eeff1a",
            "b316ff0d140941b689cc01e122c82469",
            "da169dfb9f6d424aa7039b9b4c5cd6fd",
            "347983119bc147f19506e0339f238914",
            "7ddde82d810d44fdb11c8f8cb3bd8e6e",
            "ec5c60c8acea4d3fa3bdb5e7893fe667",
            "d930c42f86bb4375b06f9e65b8cb3eba",
            "e6a012afb0dd40a7bf9b858ef111b940",
            "ecd66e1007bc4560b585e6c651dc0baa",
            "fbb7abf0456b488b8c1ce34f1ecd940f",
            "bf7f61e4de3f4e789182f2e89d08c43c",
            "cfd98dc31c794b8dbce58935064584b8",
            "3b83cef72e604ebdbd3230fbbd30839c",
            "0c0f419153f341cca3f3a6f5b3babc50",
            "553072e7dbe648ffae7719a37e7db6bc",
            "892ab796c2ff4127bbe71ede3ddd3415",
            "e864c2ca8be9438b863a753abccbbb9f",
            "f4e4c61479284f85b49343bc0cef332c",
            "b3fa44dc410d47b2afc66ec7b1d9f194",
            "958b768de2524aaab11101cf17e989ed",
            "8a08b0bf503d44258c411a656151ee7f",
            "b815c8de147d44f88f1ebf0bc379e7b4",
            "0c38740172e9434e962c88174baf69ce",
            "2152d5e5054a4cb9b64c3a400d3a400c",
            "ee908459639d4fbc9a3a1214c9880d7c",
            "4890ddd63de74b59a1123fbc94085df4",
            "57ae130e780b44a5bdf8170ee72ba35d",
            "15ec8e4bf3ef41ecab394e5004108854",
            "b8bbb0d9ba7f42feb64ef1fc23fd9e5c",
            "e5fa6b7e7d1446109ea1b0091dbc1c88",
            "65016476122c4606b2525fb15d04cabd",
            "77b57dc4a5534d8db8c720cb7f58ea58",
            "5cbceabcecb546869728f3e1ca6051d6",
            "858116ce3ed344299bba909b05add80c",
            "23d29a32f4264099afec134f8c663509",
            "f511701fc82f45889a87650557adc2af",
            "07b45ce1c5ba492da7c9ced86ce0cd81",
            "45e8a4d2261349dcb19199e8006d5abd",
            "58350931d5ac497caeb85f0f36abd8da",
            "f0a5a06ee5ae4d89892107f0c7c504c3",
            "9b93235341244881b27fc54c604a10dc",
            "df98a38752f143f9976ae4e4ab79d811",
            "8b82cf4186514ce4bb3788273a849808",
            "782a48514338428d94415662bf276399",
            "3fc6ef0691a943c3ac80beadb8457ffa",
            "91795100b6f94381bf11b1a632ffe9c0",
            "bb91939f39ae4d6199aa394f18ab7e79",
            "cb5206954b1044b983e290ac9d8f11a7",
            "6027294d496a464e8b2f5a0e4f439e0b",
            "682b0634ad4d4499a8f3271240ad2cb1",
            "a81e719a1b0c4498b7e4ff61a808f90c",
            "324424da5de94d15a5fec0803401c7c1",
            "1ca486c6a4f248d0ba4c2f951498912c",
            "b3bb565c9058403296011a5cbbc8487f",
            "752041188e5a495ebf8c3d3bb7c90d20",
            "d6a64ce897ab4aedbc792e001fc4a45a",
            "a22c8e12458747458c6a44197ad4e297",
            "6eedaba0e6d14b3cb3e84e273b20ed79",
            "85c63db23bd84b7589b6c64e29678f83",
            "d191572d3a984e9e980ce1b6dc5a77a4",
            "94cae0cdaed24d67bac8de4a76f9e9a8",
            "cff60b15dc3d48378cc5a5cc22dc9c91",
            "b62e7f169c3043738298c2a833eb7cc3",
            "87be7681cbf14773933397cb1199dfaa",
            "56fb3225660140deb53709acb4cc84f5",
            "aa6971a6e35d49c491628d468e4f55e9",
            "cc4f7f13aa92498fa7750d1ebe3020e3",
            "fa46732dc7e2472a92a0051b52659849",
            "b74d754249f24a6eb07bb13678ac0faa",
            "5e5869811a6440d69beaa00776043e4f",
            "cf9d9eebd5354a2a9d21a732fd1a9245",
            "2e58642178f94b24af5edf6a946ff8f3",
            "fa42c89d50434f48a3cb9847fdbe8a45",
            "fe5c7127f69f41c4b0c16cf80d5833e0",
            "c77fb2f4a2f349e8a94d4f00d5f05a59"
          ],
          "height": 449
        },
        "id": "sWa45riHslGI",
        "outputId": "9bb7e81b-742b-4ac2-9093-810183596d1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/65.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f24af718d0cf4505a2d0a2e242be3838"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/132k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbb7abf0456b488b8c1ce34f1ecd940f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/57.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a08b0bf503d44258c411a656151ee7f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation-00000-of-00001.parquet:   0%|          | 0.00/132k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77b57dc4a5534d8db8c720cb7f58ea58"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b82cf4186514ce4bb3788273a849808"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/1000000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3bb565c9058403296011a5cbbc8487f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56fb3225660140deb53709acb4cc84f5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Step1: Load the data and separate into train, validation and test data\n",
        "# Import necessary libraries\n",
        "# Install datasets, tokenizers library if you've not done so yet (!pip install datasets, tokenizers).\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from pathlib import Path\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "os.mkdir(\"./malaygpt\")\n",
        "os.mkdir(\"./tokenizer_en\")\n",
        "os.mkdir(\"./tokenizer_my\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_dataset = load_dataset(\"Helsinki-NLP/opus-100\", \"en-ms\", split='train')\n",
        "validation_dataset = load_dataset(\"Helsinki-NLP/opus-100\", \"en-ms\", split='validation')\n",
        "\n",
        "# limit the number of data in dataset for faster training purpose\n",
        "raw_train_dataset, rt_to_skip = random_split(train_dataset, [1500,len(train_dataset)-1500])\n",
        "raw_validation_dataset, vt_to_skip = random_split(validation_dataset, [50,len(validation_dataset)-50])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "\n",
        "def get_ds_iterator(raw_train_dataset, lang):\n",
        "  for data in raw_train_dataset:\n",
        "    yield data['translation'][lang]\n",
        "\n",
        "# Create Source Tokenizer - English\n",
        "tokenizer_en = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
        "trainer_en = BpeTrainer(min_frequency=2, special_tokens=[\"[PAD]\",\"[UNK]\",\"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "# We’ll also need to add a pre-tokenizer to split our input into words as without a pre-tokenizer, we might get tokens that overlap several words: for instance we could get a \"there is\" token since those two words often appear next to each other.\n",
        "# Using a pre-tokenizer will ensure no token is bigger than a word returned by the pre-tokenizer.\n",
        "tokenizer_en.pre_tokenizer = Whitespace()\n",
        "tokenizer_en.train_from_iterator(get_ds_iterator(raw_train_dataset, \"en\"), trainer=trainer_en)\n",
        "tokenizer_en.save(\"./tokenizer_en/tokenizer_en.json\")\n",
        "\n",
        "# Create Target Tokenizer - Malay\n",
        "tokenizer_my = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
        "trainer_my = BpeTrainer(min_frequency=2, special_tokens=[\"[PAD]\",\"[UNK]\",\"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "tokenizer_my.pre_tokenizer = Whitespace()\n",
        "tokenizer_my.train_from_iterator(get_ds_iterator(raw_train_dataset, \"ms\"), trainer=trainer_my)\n",
        "tokenizer_my.save(\"./tokenizer_my/tokenizer_my.json\")\n",
        "\n",
        "tokenizer_en = Tokenizer.from_file(\"./tokenizer_en/tokenizer_en.json\")\n",
        "tokenizer_my = Tokenizer.from_file(\"./tokenizer_my/tokenizer_my.json\")\n",
        "\n",
        "source_vocab_size = tokenizer_en.get_vocab_size()\n",
        "target_vocab_size = tokenizer_my.get_vocab_size()\n",
        "\n",
        "# to calculate the max sequence lenth in the entire training dataset for the source and target dataset\n",
        "max_seq_len_source = 0\n",
        "max_seq_len_target = 0\n",
        "\n",
        "for data in raw_train_dataset:\n",
        "    enc_ids = tokenizer_en.encode(data['translation']['en']).ids\n",
        "    dec_ids = tokenizer_my.encode(data['translation']['ms']).ids\n",
        "    max_seq_len_source = max(max_seq_len_source, len(enc_ids))\n",
        "    max_seq_len_target = max(max_seq_len_target, len(dec_ids))\n",
        "\n",
        "print(f'max_seqlen_source: {max_seq_len_source}')   #99 - can be different in your case\n",
        "print(f'max_seqlen_target: {max_seq_len_target}')   #109 - can be different in your case\n",
        "\n",
        "# to make it standard for our training we'll just take max_seq_len_source and add 20-50 to cover the additional tokens such as PAD, CLS, SEP\n",
        "max_seq_len = 155"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULqpLdqewvrQ",
        "outputId": "81adc793-af62-4059-b1c8-168f93285215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_seqlen_source: 70\n",
            "max_seqlen_target: 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step3: Prepare dataset and dataloader\n",
        "\n",
        "# Transform raw dataset to the encoded dataset that can be processed by the model\n",
        "class EncodeDataset(Dataset):\n",
        "    def __init__(self, raw_dataset, max_seq_len):\n",
        "        super().__init__()\n",
        "        self.raw_dataset = raw_dataset\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.raw_dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # fetching the single data for the given index value that consist of both english and malay language.\n",
        "        raw_text = self.raw_dataset[index]\n",
        "\n",
        "        # separating text by source and target lanaguage which will be later used for encoding.\n",
        "        source_text = raw_text['translation']['en']\n",
        "        target_text = raw_text['translation']['ms']\n",
        "\n",
        "        # Encoding source text with with english tokenizer and target text with malay tokenizer\n",
        "        source_text_encoded = tokenizer_en.encode(source_text).ids\n",
        "        target_text_encoded = tokenizer_my.encode(target_text).ids\n",
        "\n",
        "        # Convert the CLS, SEP and PAD tokens to their corresponding index id in vocabulary using tokenizer [the id would be same with either tokenizers]\n",
        "        CLS_ID = torch.tensor([tokenizer_my.token_to_id(\"[CLS]\")], dtype=torch.int64)\n",
        "        SEP_ID = torch.tensor([tokenizer_my.token_to_id(\"[SEP]\")], dtype=torch.int64)\n",
        "        PAD_ID = torch.tensor([tokenizer_my.token_to_id(\"[PAD]\")], dtype=torch.int64)\n",
        "\n",
        "        # To train the model, the sequence lenth of each input should be equal max seq length. Hence additional number of padding will be added to the input sequence if the lenth is not equal to the max seq length.\n",
        "        num_source_padding = self.max_seq_len - len(source_text_encoded) - 2\n",
        "        num_target_padding = self.max_seq_len - len(target_text_encoded) - 1\n",
        "\n",
        "        encoder_padding = torch.tensor([PAD_ID] * num_source_padding, dtype = torch.int64)\n",
        "        decoder_padding = torch.tensor([PAD_ID] * num_target_padding, dtype = torch.int64)\n",
        "\n",
        "        # encoder_input has the first token as start of senstence - CLS_ID, followed by source encoding which is then followed by the end of sentence token - SEP.\n",
        "        # To reach the required max_seq_len, addition PAD token will be added at the end.\n",
        "        encoder_input = torch.cat([CLS_ID, torch.tensor(source_text_encoded, dtype=torch.int64), SEP_ID, encoder_padding], dim=0)\n",
        "\n",
        "        # decoder_input has the first token as start of senstence - CLS_ID, followed by target encoding.\n",
        "        # To reach the required max_seq_len, addition PAD token will be added at the end. There is no end of sentence token - SEP in decoder input.\n",
        "        decoder_input = torch.cat([CLS_ID, torch.tensor(target_text_encoded, dtype=torch.int64), decoder_padding ], dim=0)\n",
        "\n",
        "        # target_label is required for the loss calculation during training to compare between the predicted and target label.\n",
        "        # target_label has the first token as target encoding followed by actual target encoding. There is no start of sentence token - CLS in target label.\n",
        "        # To reach the required max_seq_len, addition PAD token will be added at the end.\n",
        "        target_label = torch.cat([torch.tensor(target_text_encoded, dtype=torch.int64),SEP_ID,decoder_padding], dim=0)\n",
        "\n",
        "        # Since we've added extra padding token with input encoding, we don't want this token to be trained by model.\n",
        "        # So, we'll use encoder mask to nullify the padding value prior to producing output of self attention in encoder block\n",
        "        encoder_mask = (encoder_input != PAD_ID).unsqueeze(0).unsqueeze(0).int()\n",
        "\n",
        "        # We don't want any token to get influence the future token during the decoding stage. Hence, Causal mask is being implemented during masked multihead attention to handle this.\n",
        "        decoder_mask = (decoder_input != PAD_ID).unsqueeze(0).unsqueeze(0).int() & causal_mask(decoder_input.size(0))\n",
        "\n",
        "        return {\n",
        "            'encoder_input': encoder_input,\n",
        "            'decoder_input': decoder_input,\n",
        "            'target_label': target_label,\n",
        "            'encoder_mask': encoder_mask,\n",
        "            'decoder_mask': decoder_mask,\n",
        "            'source_text': source_text,\n",
        "            'target_text': target_text\n",
        "        }\n",
        "\n",
        "# Causal mask will make sure any token that comes after the current token will be masked meaning the value will be replaced by -infinity that will be converted to zero or neearly zero after softmax operation. Hence the model will just ignore these value or willn't be able to learn anything.\n",
        "def causal_mask(size):\n",
        "        # Creating a square matrix of dimensions 'size x size' filled with ones\n",
        "        mask = torch.triu(torch.ones(1, size, size), diagonal = 1).type(torch.int)\n",
        "        return mask == 0\n",
        "\n",
        "# create a dataloader to use for model training and validation\n",
        "train_ds = EncodeDataset(raw_train_dataset, max_seq_len)\n",
        "val_ds = EncodeDataset(raw_validation_dataset, max_seq_len)\n",
        "\n",
        "train_dataloader = DataLoader(train_ds, batch_size = 5, shuffle = True)\n",
        "val_dataloader = DataLoader(val_ds, batch_size = 1, shuffle = True)"
      ],
      "metadata": {
        "id": "YZNyHnlcx6kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Input embedding and positional encoding\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class EmbeddingLayer(nn.Module):\n",
        "    def __init__(self, d_model: int, vocab_size: int):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        # using pytorch models embedding layer to map token id to embeeding vector which has the shape of (vocab_size, d_model)\n",
        "        # The vocab_size is the vocabulary size of the training data created by tokenizer in step 2\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # In addition of giving input to the embedding, the extra multiplication by square root of d_model is to normalize the embedding layer output\n",
        "        embedding_output = self.embedding(input) * math.sqrt(self.d_model)\n",
        "        return embedding_output\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, max_seq_len: int, dropout_rate: float):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        pe = torch.zeros(max_seq_len, d_model)\n",
        "\n",
        "        pos = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
        "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
        "\n",
        "        # since we're expecting the input sentenses in batches so the extra dimension to cater batch number needs to be added in 0 postion\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, input_embdding):\n",
        "        input_embdding = input_embdding + (self.pe[:, :input_embdding.shape[1], :]).requires_grad_(False)   # to prevent from calculating gradient\n",
        "        return self.dropout(input_embdding)"
      ],
      "metadata": {
        "id": "0ECIzeiUx80q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Step 5: Multihead Attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model: int, num_heads: int, dropout_rate: float):\n",
        "        super().__init__()\n",
        "        # Defining dropout to prevent overfitting\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.num_heads = num_heads\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by number of heads\"\n",
        "\n",
        "        # d_k is the new dimension of each self attention heads\n",
        "        self.d_k = d_model // num_heads\n",
        "\n",
        "        # Weight matrix are defined which are all learnable parameters\n",
        "        self.W_q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.W_k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.W_v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.W_o = nn.Linear(d_model, d_model, bias=False)\n",
        "\n",
        "    def forward(self, q, k, v, encoder_mask):\n",
        "\n",
        "        # Please note that we'll be training our model with not just a single sequence but rather batches of sequence, hence we'll include batch_size in the shape\n",
        "        # query, Key and value are calculated by matrix multiplication of corresponding weights with the input embeddings\n",
        "        # Change of shape: q(batch_size, seq_len, d_model) @ W_q(d_model, d_model) => query(batch_size, seq_len, d_model) [same goes to key and value]\n",
        "        query = self.W_q(q)\n",
        "        key = self.W_k(k)\n",
        "        value = self.W_v(v)\n",
        "\n",
        "        # Dividing query, key and value into number of heads, hence new dimenstion will be d_k.\n",
        "        # Change of shape: query(batch_size, seq_len, d_model) => query(batch_size, seq_len, num_heads, d_k) -> query(batch_size,num_heads, seq_len,d_k) [same goes to key and value]\n",
        "        query = query.view(query.shape[0], query.shape[1], self.num_heads ,self.d_k).transpose(1,2)\n",
        "        key = key.view(key.shape[0], key.shape[1], self.num_heads ,self.d_k).transpose(1,2)\n",
        "        value = value.view(value.shape[0], value.shape[1], self.num_heads ,self.d_k).transpose(1,2)\n",
        "\n",
        "        # :: SELF ATTENTION BLOCK STARTS ::\n",
        "\n",
        "        # Attention score is calculated to find the similarity or relation of query with key of itself and all other embedding in the sequence\n",
        "        #  Change of shape: query(batch_size,num_heads, seq_len,d_k) @ key(batch_size,num_heads, seq_len,d_k) => attention_score(batch_size,num_heads, seq_len,seq_len)\n",
        "        attention_score = (query @ key.transpose(-2,-1))/math.sqrt(self.d_k)\n",
        "\n",
        "        # If mask is provided the attention score needs to modify as per the mask value. Refer to the details in point no 4.\n",
        "        if encoder_mask is not None:\n",
        "          attention_score.masked_fill_(encoder_mask==0, -1e9)\n",
        "\n",
        "        # Softmax operation calculates the probability distribution among all the attention scores. This will determine which embedding is more similar to the given query embedding and assign the attention weight accordingly.\n",
        "        # Change of shape: same as attention_score\n",
        "        attention_score = attention_score.softmax(dim=-1)\n",
        "\n",
        "        if self.dropout is not None:\n",
        "          attention_score = self.dropout(attention_score)\n",
        "\n",
        "        # Final step of Self attention block is to matrix multiplication of attention_weight with value embedding.\n",
        "        # Change of shape: attention_score(batch_size,num_heads, seq_len,seq_len) @  value(batch_size,num_heads, seq_len,d_k) => attention_output(batch_size,num_heads, seq_len,d_k)\n",
        "        attention_output = attention_score @ value\n",
        "\n",
        "        # :: SELF ATTENTION BLOCK ENDS ::\n",
        "\n",
        "        # Now, all the heads will be concated back to for a single head\n",
        "        # Change of shape:attention_output(batch_size,num_heads, seq_len,d_k) => attention_output(batch_size,seq_len,num_heads,d_k) => attention_output(batch_size,seq_len,d_model)\n",
        "        attention_output = attention_output.transpose(1,2).contiguous().view(attention_output.shape[0], -1, self.num_heads * self.d_k)\n",
        "\n",
        "        # Finally attention_output is matrix multiplied with output weight matrix to give the final Multi-Head attention output.\n",
        "        # The shape of the multihead_output is same as the embedding input\n",
        "        # Change of shape: attention_output(batch_size,seq_len,d_model) @ W_o(d_model, d_model) => multihead_output(batch_size, seq_len, d_model)\n",
        "        multihead_output = self.W_o(attention_output)\n",
        "\n",
        "        return multihead_output"
      ],
      "metadata": {
        "id": "B-sXiEEN-JwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Feedfoward Network, Layer Normalization and AddAndNorm\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model: int, d_ff: int, dropout_rate: float):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.layer_1 = nn.Linear(d_model, d_ff)\n",
        "        self.layer_2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.layer_2(self.dropout(torch.relu(self.layer_1(input))))\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    # def __init__(self, features:int=512, eps: float = 1e-5):\n",
        "    def __init__(self, eps: float = 1e-5):\n",
        "        super().__init__()\n",
        "        # epsilon is a very small value and is plays an important role to avoid division by zero problem\n",
        "        self.eps = eps\n",
        "        #Extra learning parameters gamma and beta are introduced to scale and shift the embedding value as the network needed.\n",
        "        self.gamma = nn.Parameter(torch.ones(512))  # 512 = advisable to initialize with same number as d_model\n",
        "        self.beta = nn.Parameter(torch.zeros(512))\n",
        "\n",
        "    def forward(self, input):\n",
        "        mean = input.mean(dim = -1, keepdim=True)\n",
        "        std = input.std(dim = -1, keepdim=True)\n",
        "        return self.gamma * (input - mean)/(std + self.eps) + self.beta\n",
        "\n",
        "class AddAndNorm(nn.Module):\n",
        "  def __init__(self, dropout_rate: float):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.layer_norm = LayerNorm()\n",
        "\n",
        "  def forward(self, input, sub_layer):\n",
        "        return input + self.dropout(sub_layer(self.layer_norm(input)))"
      ],
      "metadata": {
        "id": "koWkdu3X-aTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 7: Encoder block and Encoder\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    # def __init__(self, features: int, self_attention_block: MultiHeadAttention, feed_forward_block: FeedForward, dropout_rate: float) -> None:\n",
        "    def __init__(self, multihead_attention: MultiHeadAttention, feed_forward: FeedForward, dropout_rate: float) -> None:\n",
        "        super().__init__()\n",
        "        self.multihead_attention = multihead_attention\n",
        "        self.feed_forward = feed_forward\n",
        "        self.addnorm_1 = AddAndNorm(dropout_rate)\n",
        "        self.addnorm_2 = AddAndNorm(dropout_rate)\n",
        "\n",
        "    def forward(self, encoder_input, encoder_mask):\n",
        "        # First AddAndNorm unit taking encoder input from skip connection and adding it with the output of MultiHead attention block\n",
        "        encoder_input = self.addnorm_1(encoder_input, lambda encoder_input: self.multihead_attention(encoder_input, encoder_input, encoder_input, encoder_mask))\n",
        "        # Second AddAndNorm unit taking output of MultiHead attention block from skip connection and adding it with the output of Feedforward layer\n",
        "        encoder_input = self.addnorm_2(encoder_input, self.feed_forward)\n",
        "        return encoder_input\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, encoderblocklist: nn.ModuleList) -> None:\n",
        "        super().__init__()\n",
        "        # Encoder class initialized by taking encoderblock list\n",
        "        self.encoderblocklist = encoderblocklist\n",
        "        self.layer_norm = LayerNorm()\n",
        "\n",
        "    def forward(self, encoder_input, encoder_mask):\n",
        "        # Looping through all the encoder block - 6 times\n",
        "        for encoderblock in self.encoderblocklist:\n",
        "            encoder_input = encoderblock(encoder_input, encoder_mask)\n",
        "        # Normalize the final encoder block output and return. This encoder output will be used later on as key and value for the cross attention in decoder block\n",
        "        encoder_output = self.layer_norm(encoder_input)\n",
        "        return encoder_output"
      ],
      "metadata": {
        "id": "oCpGI95l-lLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Feedfoward Network, Layer Normalization and AddAndNorm\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model: int, d_ff: int, dropout_rate: float):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.layer_1 = nn.Linear(d_model, d_ff)\n",
        "        self.layer_2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.layer_2(self.dropout(torch.relu(self.layer_1(input))))\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    # def __init__(self, features:int=512, eps: float = 1e-5):\n",
        "    def __init__(self, eps: float = 1e-5):\n",
        "        super().__init__()\n",
        "        # epsilon is a very small value and is plays an important role to avoid division by zero problem\n",
        "        self.eps = eps\n",
        "        #Extra learning parameters gamma and beta are introduced to scale and shift the embedding value as the network needed.\n",
        "        self.gamma = nn.Parameter(torch.ones(512))  # 512 = advisable to initialize with same number as d_model\n",
        "        self.beta = nn.Parameter(torch.zeros(512))\n",
        "\n",
        "    def forward(self, input):\n",
        "        mean = input.mean(dim = -1, keepdim=True)\n",
        "        std = input.std(dim = -1, keepdim=True)\n",
        "        return self.gamma * (input - mean)/(std + self.eps) + self.beta\n",
        "\n",
        "class AddAndNorm(nn.Module):\n",
        "  def __init__(self, dropout_rate: float):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.layer_norm = LayerNorm()\n",
        "\n",
        "  def forward(self, input, sub_layer):\n",
        "        return input + self.dropout(sub_layer(self.layer_norm(input)))"
      ],
      "metadata": {
        "id": "WGiJC9Ql-qyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 7: Encoder block and Encoder\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    # def __init__(self, features: int, self_attention_block: MultiHeadAttention, feed_forward_block: FeedForward, dropout_rate: float) -> None:\n",
        "    def __init__(self, multihead_attention: MultiHeadAttention, feed_forward: FeedForward, dropout_rate: float) -> None:\n",
        "        super().__init__()\n",
        "        self.multihead_attention = multihead_attention\n",
        "        self.feed_forward = feed_forward\n",
        "        self.addnorm_1 = AddAndNorm(dropout_rate)\n",
        "        self.addnorm_2 = AddAndNorm(dropout_rate)\n",
        "\n",
        "    def forward(self, encoder_input, encoder_mask):\n",
        "        # First AddAndNorm unit taking encoder input from skip connection and adding it with the output of MultiHead attention block\n",
        "        encoder_input = self.addnorm_1(encoder_input, lambda encoder_input: self.multihead_attention(encoder_input, encoder_input, encoder_input, encoder_mask))\n",
        "        # Second AddAndNorm unit taking output of MultiHead attention block from skip connection and adding it with the output of Feedforward layer\n",
        "        encoder_input = self.addnorm_2(encoder_input, self.feed_forward)\n",
        "        return encoder_input\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, encoderblocklist: nn.ModuleList) -> None:\n",
        "        super().__init__()\n",
        "        # Encoder class initialized by taking encoderblock list\n",
        "        self.encoderblocklist = encoderblocklist\n",
        "        self.layer_norm = LayerNorm()\n",
        "\n",
        "    def forward(self, encoder_input, encoder_mask):\n",
        "        # Looping through all the encoder block - 6 times\n",
        "        for encoderblock in self.encoderblocklist:\n",
        "            encoder_input = encoderblock(encoder_input, encoder_mask)\n",
        "        # Normalize the final encoder block output and return. This encoder output will be used later on as key and value for the cross attention in decoder block\n",
        "        encoder_output = self.layer_norm(encoder_input)\n",
        "        return encoder_output"
      ],
      "metadata": {
        "id": "juuGarSi_BHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 8: Decoder block and decoder and the projection\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    # def __init__(self, features: int, self_attention_block: MultiHeadAttention, cross_attention_block: MultiHeadAttention, feed_forward_block: FeedForward, dropout_rate: float) -> None:\n",
        "    def __init__(self, masked_multihead_attention: MultiHeadAttention, cross_multihead_attention: MultiHeadAttention, feed_forward: FeedForward, dropout_rate: float) -> None:\n",
        "        super().__init__()\n",
        "        self.masked_multihead_attention = masked_multihead_attention\n",
        "        self.cross_multihead_attention = cross_multihead_attention\n",
        "        self.feed_forward = feed_forward\n",
        "        self.addnorm_1 = AddAndNorm(dropout_rate)\n",
        "        self.addnorm_2 = AddAndNorm(dropout_rate)\n",
        "        self.addnorm_3 = AddAndNorm(dropout_rate)\n",
        "\n",
        "    def forward(self, decoder_input, encoder_output, encoder_mask, decoder_mask):\n",
        "        # First AddAndNorm unit taking decoder input from skip connection and adding it with the output of Masked Multi-Head attention block\n",
        "        decoder_input = self.addnorm_1(decoder_input, lambda decoder_input: self.masked_multihead_attention(decoder_input, decoder_input, decoder_input, decoder_mask))\n",
        "        # Second AddAndNorm unit taking output of Masked Multi-Head attention block from skip connection and adding it with the output of MultiHead attention block\n",
        "        decoder_input = self.addnorm_2(decoder_input, lambda decoder_input: self.cross_multihead_attention(decoder_input, encoder_output, encoder_output, encoder_mask))\n",
        "        # Third AddAndNorm unit taking output of MultiHead attention block from skip connection and adding it with the output of Feedforward layer\n",
        "        decoder_input = self.addnorm_3(decoder_input, self.feed_forward)\n",
        "        return decoder_input\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    # def __init__(self, features: int, layers: nn.ModuleList) -> None:\n",
        "    def __init__(self, decoderblocklist: nn.ModuleList) -> None:\n",
        "        super().__init__()\n",
        "        self.decoderblocklist = decoderblocklist\n",
        "        self.layer_norm = LayerNorm()\n",
        "\n",
        "    def forward(self, decoder_input, encoder_output, encoder_mask, decoder_mask):\n",
        "        for decoderblock in self.decoderblocklist:\n",
        "            decoder_input = decoderblock(decoder_input, encoder_output, encoder_mask, decoder_mask)\n",
        "        decoder_output = self.layer_norm(decoder_input)\n",
        "        return decoder_output\n",
        "\n",
        "class ProjectionLayer(nn.Module):\n",
        "    def __init__(self, d_model, vocab_size) -> None:\n",
        "        super().__init__()\n",
        "        self.projection_layer = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, decoder_output) -> None:\n",
        "        # Projection layer first take in decoder output and feed into the linear layer of shape (d_model, vocab_size)\n",
        "        #Change in shape: decoder_output(batch_size, seq_len, d_model) @ linear_layer(d_model, vocab_size) => output(batch_size, seq_len, vocab_size)\n",
        "        output = self.projection_layer(decoder_output)\n",
        "        return output"
      ],
      "metadata": {
        "id": "i8Y-xz11_FF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 9: Create and build Transfomer\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, encoder: Encoder, decoder: Decoder, source_embed: EmbeddingLayer, target_embed: EmbeddingLayer, source_pos: PositionalEncoding, target_pos: PositionalEncoding, projection_layer: ProjectionLayer) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.source_embed = source_embed\n",
        "        self.source_pos = source_pos\n",
        "        self.encoder = encoder\n",
        "\n",
        "        self.target_embed = target_embed\n",
        "        self.target_pos = target_pos\n",
        "        self.decoder = decoder\n",
        "\n",
        "        self.projection_layer = projection_layer\n",
        "\n",
        "    def encode(self, encoder_input, encoder_mask):\n",
        "        encoder_input = self.source_embed(encoder_input)\n",
        "        encoder_input = self.source_pos(encoder_input)\n",
        "        encoder_output = self.encoder(encoder_input, encoder_mask)\n",
        "        return encoder_output\n",
        "\n",
        "    def decode(self, encoder_output, encoder_mask, decoder_input, decoder_mask):\n",
        "        decoder_input = self.target_embed(decoder_input)\n",
        "        decoder_input = self.target_pos(decoder_input)\n",
        "        decoder_output = self.decoder(decoder_input, encoder_output, encoder_mask, decoder_mask)\n",
        "        return decoder_output\n",
        "\n",
        "    def project(self, decoder_output):\n",
        "        return self.projection_layer(decoder_output)\n",
        "\n",
        "def build_model(source_vocab_size: int, target_vocab_size: int, source_seq_len: int, target_seq_len: int, d_model: int=512, num_blocks: int=6, num_heads: int=8, dropout_rate: float=0.1, d_ff: int=2048) -> Transformer:\n",
        "    # Create the embedding layers\n",
        "    source_embed = EmbeddingLayer(d_model, source_vocab_size)\n",
        "    target_embed = EmbeddingLayer(d_model, target_vocab_size)\n",
        "\n",
        "    # Create the positional encoding layers\n",
        "    source_pos = PositionalEncoding(d_model, source_seq_len, dropout_rate)\n",
        "    target_pos = PositionalEncoding(d_model, target_seq_len, dropout_rate)\n",
        "\n",
        "    # Create the encoder-block-list\n",
        "    encoderblocklist = []\n",
        "    for _ in range(num_blocks):\n",
        "        multihead_attention = MultiHeadAttention(d_model, num_heads, dropout_rate)\n",
        "        feed_forward = FeedForward(d_model, d_ff, dropout_rate)\n",
        "        encoder_block = EncoderBlock(multihead_attention, feed_forward, dropout_rate)\n",
        "        encoderblocklist.append(encoder_block)\n",
        "    # Create the encoder\n",
        "    encoder = Encoder(nn.ModuleList(encoderblocklist))\n",
        "\n",
        "    # Create the decoder-block-list\n",
        "    decoderblocklist = []\n",
        "    for _ in range(num_blocks):\n",
        "        masked_multihead_attention = MultiHeadAttention(d_model,num_heads, dropout_rate)\n",
        "        cross_multihead_attention = MultiHeadAttention(d_model, num_heads, dropout_rate)\n",
        "        feed_forward = FeedForward(d_model, d_ff, dropout_rate)\n",
        "        decoder_block = DecoderBlock(masked_multihead_attention, cross_multihead_attention, feed_forward, dropout_rate)\n",
        "        decoderblocklist.append(decoder_block)\n",
        "    # Create the decoder\n",
        "    decoder = Decoder(nn.ModuleList(decoderblocklist))\n",
        "\n",
        "    # Create the projection layer\n",
        "    projection_layer = ProjectionLayer(d_model, target_vocab_size)\n",
        "\n",
        "    # Now that we've initialized all the required blocks of transformer, we can now inititiate a model\n",
        "    model = Transformer(encoder, decoder, source_embed, target_embed, source_pos, target_pos, projection_layer)\n",
        "\n",
        "    # For the first time, we'll initialize the model parameters using xavier uniform method. Once training begings the parameters will be updated by the network\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Let's build the the final model.\n",
        "model = build_model(tokenizer_en.get_vocab_size(), tokenizer_my.get_vocab_size(),max_seq_len, max_seq_len, d_model=512).to(device)\n",
        "\n",
        "# Let's look at the architecture that we've just build ourself\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "O1Xz3G0O_P9i",
        "outputId": "19cf934b-8866-4e34-d1c7-ea177041fa21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer(\n",
            "  (source_embed): EmbeddingLayer(\n",
            "    (embedding): Embedding(1892, 512)\n",
            "  )\n",
            "  (source_pos): PositionalEncoding(\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): Encoder(\n",
            "    (encoderblocklist): ModuleList(\n",
            "      (0-5): 6 x EncoderBlock(\n",
            "        (multihead_attention): MultiHeadAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (W_q): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_k): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_v): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_o): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): FeedForward(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (layer_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        )\n",
            "        (addnorm_1): AddAndNorm(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_norm): LayerNorm()\n",
            "        )\n",
            "        (addnorm_2): AddAndNorm(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "  )\n",
            "  (target_embed): EmbeddingLayer(\n",
            "    (embedding): Embedding(2115, 512)\n",
            "  )\n",
            "  (target_pos): PositionalEncoding(\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (decoderblocklist): ModuleList(\n",
            "      (0-5): 6 x DecoderBlock(\n",
            "        (masked_multihead_attention): MultiHeadAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (W_q): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_k): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_v): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_o): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (cross_multihead_attention): MultiHeadAttention(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (W_q): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_k): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_v): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (W_o): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): FeedForward(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (layer_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        )\n",
            "        (addnorm_1): AddAndNorm(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_norm): LayerNorm()\n",
            "        )\n",
            "        (addnorm_2): AddAndNorm(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_norm): LayerNorm()\n",
            "        )\n",
            "        (addnorm_3): AddAndNorm(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "  )\n",
            "  (projection_layer): ProjectionLayer(\n",
            "    (projection_layer): Linear(in_features=512, out_features=2115, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 10: Training and Validation of malayGPT\n",
        "\n",
        "def run_validation(model, validation_ds, tokenizer_en, tokenizer_my, max_seq_len, device, print_msg, global_step):\n",
        "    model.eval()\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_ds:\n",
        "            count += 1\n",
        "            encoder_input = batch[\"encoder_input\"].to(device)\n",
        "            encoder_mask = batch[\"encoder_mask\"].to(device)\n",
        "\n",
        "            cls_id = tokenizer_my.token_to_id('[CLS]')\n",
        "            sep_id = tokenizer_my.token_to_id('[SEP]')\n",
        "\n",
        "            # Computing the output of the encoder for the source sequence\n",
        "            encoder_output = model.encode(encoder_input, encoder_mask)\n",
        "            # for prediction task, the first token that goes in decoder input is the [CLS] token\n",
        "            decoder_input = torch.empty(1, 1).fill_(cls_id).type_as(encoder_input).to(device)\n",
        "            # since we need to keep adding the output back to the input until the [SEP] - end token is received.\n",
        "            while True:\n",
        "                # check if the max length is received\n",
        "                if decoder_input.size(1) == max_seq_len:\n",
        "                    break\n",
        "\n",
        "                # recreate mask each time the new output is added the decoder input for next token prediction\n",
        "                decoder_mask = causal_mask(decoder_input.size(1)).type_as(encoder_mask).to(device)\n",
        "\n",
        "                # apply projection only to the next token\n",
        "                out = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask)\n",
        "\n",
        "                # apply projection only to the next token\n",
        "                prob = model.project(out[:, -1])\n",
        "\n",
        "                # select the token with highest probablity which is a greedy search implementation\n",
        "                _, next_word = torch.max(prob, dim=1)\n",
        "                decoder_input = torch.cat(\n",
        "                    [decoder_input, torch.empty(1, 1).type_as(encoder_input).fill_(next_word.item()).to(device)], dim=1\n",
        "                )\n",
        "                # check if the new token is the end of token\n",
        "                if next_word == sep_id:\n",
        "                    break\n",
        "            # final output is the concatinated decoder input till the end token is reached\n",
        "            model_out = decoder_input.squeeze(0)\n",
        "\n",
        "            source_text = batch[\"source_text\"][0]\n",
        "            target_text = batch[\"target_text\"][0]\n",
        "            model_out_text = tokenizer_my.decode(model_out.detach().cpu().numpy())\n",
        "\n",
        "            # Print the source, target and model output\n",
        "            print_msg('-'*55)\n",
        "            # print_msg(f\"{f'SOURCE: ':>12}{source_text}\")\n",
        "            # print_msg(f\"{f'TARGET: ':>12}{target_text}\")\n",
        "            # print_msg(f\"{f'PREDICTED: ':>12}{model_out_text}\")\n",
        "            print_msg(f'Source Text: {source_text}')\n",
        "            print_msg(f'Target Text: {target_text}')\n",
        "            print_msg(f'Predicted by MalayGPT: {model_out_text}')\n",
        "\n",
        "            if count == 2:\n",
        "                break\n",
        "\n",
        "def train_model(preload_epoch=None):\n",
        "    # The entire training, validation cycle will run for 20 cycles or epochs.\n",
        "    EPOCHS = 3\n",
        "    initial_epoch = 0\n",
        "    global_step = 0\n",
        "\n",
        "    # Adam is one of the most commonly used optimization algorithms that hold the current state and will update the parameters based on the computed gradients.\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, eps=1e-9)\n",
        "\n",
        "    # If the preload_epoch is not none, that means the training will start with the weights, optimizer that has been last saved and start with preload epoch + 1\n",
        "    if preload_epoch is not None:\n",
        "      model_filename = f\"./malaygpt/model_{preload_epoch}.pt\"\n",
        "      state = torch.load(model_filename)\n",
        "      model.load_state_dict(state['model_state_dict'])\n",
        "      initial_epoch = state['epoch'] + 1\n",
        "      optimizer.load_state_dict(state['optimizer_state_dict'])\n",
        "      global_step = state['global_step']\n",
        "\n",
        "    # The CrossEntropyLoss loss function computes the difference between the projection output and target label.\n",
        "    loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer_en.token_to_id('[PAD]'), label_smoothing=0.1).to(device)\n",
        "\n",
        "    for epoch in range(initial_epoch, EPOCHS):\n",
        "        # torch.cuda.empty_cache()\n",
        "        model.train()\n",
        "        batch_iterator = tqdm(train_dataloader, desc=f\"Processing Epoch {epoch:02d}\")\n",
        "        for batch in batch_iterator:\n",
        "            encoder_input = batch['encoder_input'].to(device) # (b, seq_len)\n",
        "            decoder_input = batch['decoder_input'].to(device) # (B, seq_len)\n",
        "            encoder_mask = batch['encoder_mask'].to(device) # (B, 1, 1, seq_len)\n",
        "            decoder_mask = batch['decoder_mask'].to(device) # (B, 1, seq_len, seq_len)\n",
        "            target_label = batch['target_label'].to(device) # (B, seq_len)\n",
        "\n",
        "            # Run the tensors through the encoder, decoder and the projection layer\n",
        "            encoder_output = model.encode(encoder_input, encoder_mask) # (B, seq_len, d_model)\n",
        "            decoder_output = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask) # (B, seq_len, d_model)\n",
        "            projection_output = model.project(decoder_output) # (B, seq_len, vocab_size)\n",
        "\n",
        "            # Compute the loss using a simple cross entropy\n",
        "            loss = loss_fn(projection_output.view(-1, tokenizer_my.get_vocab_size()), target_label.view(-1))\n",
        "            batch_iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\"})\n",
        "\n",
        "            # Backpropagate the loss\n",
        "            loss.backward()\n",
        "\n",
        "            # Update the weights\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "        # VALIDATION BLOCK STARTS HERE [Runs every epoch after the training block is complete]\n",
        "        run_validation(model, val_dataloader, tokenizer_en, tokenizer_my, max_seq_len, device, lambda msg: batch_iterator.write(msg), global_step)\n",
        "\n",
        "        # Save the model at the end of every epoch\n",
        "        model_filename = f\"./malaygpt/model_{epoch}.pt\"\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'global_step': global_step\n",
        "        }, model_filename)\n",
        "\n",
        "# Train our model\n",
        "train_model(preload_epoch=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejXRKXTZ_bJ7",
        "outputId": "8515a175-f121-4cbb-f309-c09a5444c99b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 00: 100%|██████████| 300/300 [22:31<00:00,  4.50s/it, loss=5.474]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: One more sec, okay? Hold on, one second. Don't freak.\n",
            "Target Text: Uh, uh, uh, tunggu kejap, jangan takut.\n",
            "Predicted by MalayGPT: - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "-------------------------------------------------------\n",
            "Source Text: I just don't care to die.\n",
            "Target Text: Aku hanya tidak peduli mati.\n",
            "Predicted by MalayGPT: Saya saya , saya .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 01: 100%|██████████| 300/300 [22:33<00:00,  4.51s/it, loss=5.755]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: All right, 10 seconds to go and back on.\n",
            "Target Text: Baiklah, 10 saat untuk pergi.\n",
            "Predicted by MalayGPT: - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "-------------------------------------------------------\n",
            "Source Text: I just don't care to die.\n",
            "Target Text: Aku hanya tidak peduli mati.\n",
            "Predicted by MalayGPT: - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 02: 100%|██████████| 300/300 [22:28<00:00,  4.49s/it, loss=5.719]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Source Text: Ghosts come out from everywhere!\n",
            "Target Text: Hantu keluar dari mana-mana!\n",
            "Predicted by MalayGPT: - Tak , saya !\n",
            "-------------------------------------------------------\n",
            "Source Text: I just don't care to die.\n",
            "Target Text: Aku hanya tidak peduli mati.\n",
            "Predicted by MalayGPT: Saya boleh saya .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 11: Finally testing our malayGPT model to translated new sentences. Let's give it a try.\n",
        "\n",
        "def malaygpt(user_input_text):\n",
        "\n",
        "    # validation using input text\n",
        "    user_input_text = str(user_input_text).strip()\n",
        "\n",
        "    # Let's get the model Define the device, tokenizers, and model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    tokenizer_en = Tokenizer.from_file(\"./tokenizer_en/tokenizer_en.json\")\n",
        "    tokenizer_my = Tokenizer.from_file(\"./tokenizer_my/tokenizer_my.json\")\n",
        "\n",
        "    # Build our model\n",
        "    # model = build_model(tokenizer_en.get_vocab_size(), tokenizer_my.get_vocab_size(), max_seq_len, max_seq_len, d_model=512).to(device)\n",
        "    # model = get_model(tokenizer_en.get_vocab_size(), tokenizer_my.get_vocab_size()).to(device)\n",
        "    model = build_model(tokenizer_en.get_vocab_size(), tokenizer_my.get_vocab_size(),max_seq_len, max_seq_len, d_model=512).to(device)\n",
        "\n",
        "    # Load the specific checkpoint of the model that you've saved during training.\n",
        "    checkpoint_number = 9    # for this test, I am taking checkpoint number 10\n",
        "    model_filename = f\"./malaygpt/model_{checkpoint_number}.pt\"\n",
        "    state = torch.load(model_filename)\n",
        "    model.load_state_dict(state['model_state_dict'])\n",
        "\n",
        "    # Lets beging the inferencing\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Precompute the encoder output and reuse it for every generation step\n",
        "        source_text_encoding = tokenizer_en.encode(user_input_text)\n",
        "        source_text_encoding = torch.cat([\n",
        "            torch.tensor([tokenizer_en.token_to_id('[CLS]')], dtype=torch.int64),\n",
        "            torch.tensor(source_text_encoding.ids, dtype=torch.int64),\n",
        "            torch.tensor([tokenizer_en.token_to_id('[SEP]')], dtype=torch.int64),\n",
        "            torch.tensor([tokenizer_en.token_to_id('[PAD]')] * (max_seq_len - len(source_text_encoding.ids) - 2), dtype=torch.int64)\n",
        "        ], dim=0).to(device)\n",
        "        source_mask = (source_text_encoding != tokenizer_en.token_to_id('[PAD]')).unsqueeze(0).unsqueeze(0).int().to(device)\n",
        "        encoder_output = model.encode(source_text_encoding, source_mask)\n",
        "\n",
        "        # Initialize the decoder input with the sos token\n",
        "        decoder_input = torch.empty(1, 1).fill_(tokenizer_my.token_to_id('[CLS]')).type_as(source_text_encoding).to(device)\n",
        "\n",
        "        # Generate the translation word by word\n",
        "        while decoder_input.size(1) < max_seq_len:\n",
        "            # build mask for target and calculate output\n",
        "            decoder_mask = torch.triu(torch.ones((1, decoder_input.size(1), decoder_input.size(1))), diagonal=1).type(torch.int).type_as(source_mask).to(device)\n",
        "            out = model.decode(encoder_output, source_mask, decoder_input, decoder_mask)\n",
        "\n",
        "            # project next token\n",
        "            prob = model.project(out[:, -1])\n",
        "            _, next_word = torch.max(prob, dim=1)\n",
        "            decoder_input = torch.cat([decoder_input, torch.empty(1, 1).type_as(source_text_encoding).fill_(next_word.item()).to(device)], dim=1)\n",
        "\n",
        "            # print the translated word\n",
        "            print(f\"{tokenizer_my.decode([next_word.item()])}\", end=' ')\n",
        "\n",
        "            # break if we predict the end of sentence token\n",
        "            if next_word == tokenizer_my.token_to_id('[SEP]'):\n",
        "                break\n",
        "\n",
        "    # convert ids to tokens\n",
        "    return tokenizer_my.decode(decoder_input[0].tolist())"
      ],
      "metadata": {
        "id": "MgAvv6ZjlJm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "#Step 11: Finally testing our malayGPT model to translated new sentences. Let's give it a try.\n",
        "\n",
        "def malaygpt(user_input_text):\n",
        "\n",
        "    # validation using input text\n",
        "    user_input_text = str(user_input_text).strip()\n",
        "# Let's get the model Define the device, tokenizers, and model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "LWgqWGyDmomH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input_text = \"Good\"\n",
        "translated_text = malaygpt(user_input_text)\n",
        "print(f\"User input(in English): {user_input_text}\")\n",
        "print(f\"User input(in Malay): {translated_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "g04h_z2qlUME",
        "outputId": "c15a93ed-6321-4816-af36-90a652a58884"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'malaygpt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-68175a06be46>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0muser_input_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Good\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtranslated_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmalaygpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"User input(in English): {user_input_text}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"User input(in Malay): {translated_text}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'malaygpt' is not defined"
          ]
        }
      ]
    }
  ]
}